{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23cae4d4",
   "metadata": {},
   "source": [
    "# Classification Models Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a2447",
   "metadata": {},
   "source": [
    "#### import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b874c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6527716",
   "metadata": {},
   "source": [
    "#### load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b60317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  physical_score  test_result\n",
      "0  33.0            40.7            1\n",
      "1  50.0            37.2            1\n",
      "2  52.0            24.7            0\n",
      "3  56.0            31.0            0\n",
      "4  35.0            42.9            1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hearing_test.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466544c",
   "metadata": {},
   "source": [
    "#### data cleansing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46634363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide x and y\n",
    "x = df.drop('test_result', axis=1)\n",
    "y = df['test_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c791e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Trial 1 --\n",
      "Naive Bayes         :  91.00\n",
      "SVM                 :  92.40\n",
      "Decision Tree       :  89.00\n",
      "Random Forest       :  89.80\n",
      "Logistic Regression :  90.50\n",
      "KNN                 :  91.30\n",
      "\n",
      "winner for trial-1 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 2 --\n",
      "Naive Bayes         :  90.90\n",
      "SVM                 :  92.70\n",
      "Decision Tree       :  88.70\n",
      "Random Forest       :  90.30\n",
      "Logistic Regression :  91.20\n",
      "KNN                 :  91.80\n",
      "\n",
      "winner for trial-2 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 3 --\n",
      "Naive Bayes         :  90.20\n",
      "SVM                 :  91.30\n",
      "Decision Tree       :  86.40\n",
      "Random Forest       :  88.40\n",
      "Logistic Regression :  90.20\n",
      "KNN                 :  90.90\n",
      "\n",
      "winner for trial-3 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 4 --\n",
      "Naive Bayes         :  90.40\n",
      "SVM                 :  92.10\n",
      "Decision Tree       :  88.30\n",
      "Random Forest       :  89.40\n",
      "Logistic Regression :  91.10\n",
      "KNN                 :  91.30\n",
      "\n",
      "winner for trial-4 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 5 --\n",
      "Naive Bayes         :  91.70\n",
      "SVM                 :  93.30\n",
      "Decision Tree       :  88.20\n",
      "Random Forest       :  90.10\n",
      "Logistic Regression :  92.50\n",
      "KNN                 :  92.80\n",
      "\n",
      "winner for trial-5 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 6 --\n",
      "Naive Bayes         :  91.50\n",
      "SVM                 :  91.00\n",
      "Decision Tree       :  87.90\n",
      "Random Forest       :  89.30\n",
      "Logistic Regression :  91.70\n",
      "KNN                 :  90.60\n",
      "\n",
      "winner for trial-6 is = Logistic Regression\n",
      "\n",
      "\n",
      "-- Trial 7 --\n",
      "Naive Bayes         :  90.40\n",
      "SVM                 :  92.40\n",
      "Decision Tree       :  89.00\n",
      "Random Forest       :  90.50\n",
      "Logistic Regression :  90.90\n",
      "KNN                 :  91.90\n",
      "\n",
      "winner for trial-7 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 8 --\n",
      "Naive Bayes         :  89.80\n",
      "SVM                 :  91.30\n",
      "Decision Tree       :  88.00\n",
      "Random Forest       :  89.10\n",
      "Logistic Regression :  89.90\n",
      "KNN                 :  91.40\n",
      "\n",
      "winner for trial-8 is = KNN\n",
      "\n",
      "\n",
      "-- Trial 9 --\n",
      "Naive Bayes         :  90.80\n",
      "SVM                 :  92.70\n",
      "Decision Tree       :  87.80\n",
      "Random Forest       :  90.20\n",
      "Logistic Regression :  91.00\n",
      "KNN                 :  92.00\n",
      "\n",
      "winner for trial-9 is = SVM\n",
      "\n",
      "\n",
      "-- Trial 10 --\n",
      "Naive Bayes         :  90.20\n",
      "SVM                 :  92.00\n",
      "Decision Tree       :  87.80\n",
      "Random Forest       :  88.90\n",
      "Logistic Regression :  91.50\n",
      "KNN                 :  91.30\n",
      "\n",
      "winner for trial-10 is = SVM\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trials = 10\n",
    "accuracies = []\n",
    "for trial in range(trials):\n",
    "    # plsit the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "    \n",
    "    # dictionary to hold the result\n",
    "    accuracies.append({ \n",
    "        \"Naive Bayes\": nb(),\n",
    "        \"SVM\": svm(),\n",
    "        \"Decision Tree\": decision_tree(),\n",
    "        \"Random Forest\": random_forest(),\n",
    "        \"Logistic Regression\": logistic_regression(),\n",
    "        \"KNN\": knn()\n",
    "    })\n",
    "\n",
    "    \n",
    "for trial in range(trials):\n",
    "    info = accuracies[trial]\n",
    "\n",
    "    max_score = 0.0\n",
    "    winner = ''\n",
    "    print(f\"-- Trial {trial + 1} --\")\n",
    "\n",
    "    for key in info.keys():\n",
    "        print(f\"{key:<20}: {info[key]}\")\n",
    "        if float(info[key]) > max_score:\n",
    "            max_score = float(info[key])\n",
    "            winner = key\n",
    "    \n",
    "    print()\n",
    "    print(f\"winner for trial-{trial + 1} is = {winner}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d0355e",
   "metadata": {},
   "source": [
    "#### model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd7221",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84088f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "    # create the model\n",
    "    model = LogisticRegressionCV()\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5e292",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034c4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb():\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "    # create the model\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ea59f",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b137ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm():\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # create the model\n",
    "    model = SVC(C=2.0)\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01634c2a",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87db00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "    # create the model\n",
    "    model = KNeighborsClassifier()\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bab376",
   "metadata": {},
   "source": [
    "#### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac52e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    # create the model\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8e1c7",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eeda69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # create the model\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return evaluate_model(model, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99cbac",
   "metadata": {},
   "source": [
    "#### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4da55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, name):\n",
    "    # predict the values for x_test\n",
    "    y_prediction = model.predict(x_test)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    return f\"{accuracy_score(y_test, y_prediction) * 100: 0.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd5d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240eab50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
